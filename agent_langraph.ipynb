{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "import os\n",
    "os.environ['NVIDIA_API_KEY']=os.getenv('NVIDIA_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings, GoogleGenerativeAI\n",
    "# from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", api_key=\"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\")  #reduce inference cost\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Mumbai weather'}, 'id': 'chatcmpl-tool-960eb884b7d34377bcc4feda391c09cf', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in Mumbai?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in Mumbai?'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-960eb884b7d34377bcc4feda391c09cf', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"Mumbai weather\"}'}}]}, response_metadata={'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'chatcmpl-tool-960eb884b7d34377bcc4feda391c09cf', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"Mumbai weather\"}'}}], 'token_usage': {'prompt_tokens': 385, 'total_tokens': 414, 'completion_tokens': 29}, 'finish_reason': 'tool_calls', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-aacb883a-10f7-4aff-ba46-c948fde2e1c6-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Mumbai weather'}, 'id': 'chatcmpl-tool-960eb884b7d34377bcc4feda391c09cf', 'type': 'tool_call'}], role='assistant'),\n",
       "  ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Mumbai\\', \\'region\\': \\'Maharashtra\\', \\'country\\': \\'India\\', \\'lat\\': 18.98, \\'lon\\': 72.83, \\'tz_id\\': \\'Asia/Kolkata\\', \\'localtime_epoch\\': 1725891132, \\'localtime\\': \\'2024-09-09 19:42\\'}, \\'current\\': {\\'last_updated_epoch\\': 1725890400, \\'last_updated\\': \\'2024-09-09 19:30\\', \\'temp_c\\': 29.1, \\'temp_f\\': 84.4, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1004.0, \\'pressure_in\\': 29.65, \\'precip_mm\\': 0.42, \\'precip_in\\': 0.02, \\'humidity\\': 70, \\'cloud\\': 75, \\'feelslike_c\\': 34.6, \\'feelslike_f\\': 94.2, \\'windchill_c\\': 27.9, \\'windchill_f\\': 82.3, \\'heatindex_c\\': 31.9, \\'heatindex_f\\': 89.5, \\'dewpoint_c\\': 23.8, \\'dewpoint_f\\': 74.9, \\'vis_km\\': 3.0, \\'vis_miles\\': 1.0, \\'uv\\': 1.0, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\\'url\\': \\'https://www.msn.com/en-in/news/India/mumbai-weather-and-aqi-today-warm-start-at-26-98-c-check-weather-forecast-for-september-9-2024/ar-AA1qdRc8\\', \\'content\\': \"The temperature in Mumbai today, on September 9, 2024, is 27.75 °C. The day\\'s forecast indicates a minimum and maximum temperature of 26.98 °C and 28.7 °C, respectively. The relative humidity ...\"}, {\\'url\\': \\'https://www.easeweather.com/asia/india/maharashtra/mumbai-suburban/mumbai/september\\', \\'content\\': \"Weather in Mumbai for September 2024 Until now, September 2024 in Mumbai is slightly cooler than the historical average by -0.7\\\\xa0°C. In general, the average temperature in Mumbai at the beginning of September is 28.3\\\\xa0°C. Is September a good time to visit Mumbai? Mumbai in September average weather Temperatures trend during September in Mumbai Are you interested in traveling to Mumbai in September? Mumbai in September - FAQ What to pack to Mumbai in September? As you prepare for your trip to Mumbai in September, it\\'s important to consider the typical weather patterns for the time of year. Below is a carefully tailored packing list to ensure that your time in Mumbai, during September, is comfortable and enjoyable, regardless of the weather conditions.\"}, {\\'url\\': \\'https://www.weather2travel.com/india/mumbai/september/\\', \\'content\\': \\'Check more long-term weather averages for Mumbai in September before you book your next holiday to India in 2024/2025. 30. 30°C max day temperature. 6. 6 hours of sunshine per day. 13. 13 days with some rainfall. 25. 25°C min night temperature.\\'}]', name='tavily_search_results_json', tool_call_id='chatcmpl-tool-960eb884b7d34377bcc4feda391c09cf'),\n",
       "  AIMessage(content='The current weather in Mumbai is 29.1 degrees Celsius, with a misty condition and a wind speed of 9 km/h from the west. The temperature is expected to be around 27.75 degrees Celsius during the day, with a minimum temperature of 26.98 degrees Celsius and a maximum temperature of 28.7 degrees Celsius. It is also expected to be relatively humid, with a humidity level of 70%.', response_metadata={'role': 'assistant', 'content': 'The current weather in Mumbai is 29.1 degrees Celsius, with a misty condition and a wind speed of 9 km/h from the west. The temperature is expected to be around 27.75 degrees Celsius during the day, with a minimum temperature of 26.98 degrees Celsius and a maximum temperature of 28.7 degrees Celsius. It is also expected to be relatively humid, with a humidity level of 70%.', 'token_usage': {'prompt_tokens': 1225, 'total_tokens': 1313, 'completion_tokens': 88}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-557d279b-b210-47de-b6bc-10927481db93-0', role='assistant')]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in Mumbai is 29.1 degrees Celsius, with a misty condition and a wind speed of 9 km/h from the west. The temperature is expected to be around 27.75 degrees Celsius during the day, with a minimum temperature of 26.98 degrees Celsius and a maximum temperature of 28.7 degrees Celsius. It is also expected to be relatively humid, with a humidity level of 70%.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather'}, 'id': 'chatcmpl-tool-bc0386be391a47b98292875bd6dce6a8', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Mumbai weather'}, 'id': 'chatcmpl-tool-152fce9d2c6d481980e8c8f0e17b9224', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and Mumbai?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is partly cloudy with a temperature of 57.9 degrees Fahrenheit and a humidity of 97%. The wind is blowing at 6.8 kilometers per hour from the north.\\n\\nThe current weather in Mumbai is misty with a temperature of 84.4 degrees Fahrenheit and a humidity of 70%. The wind is blowing at 9 kilometers per hour from the west.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, the query was modified to produce more consistent results. \n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "model = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", api_key=\"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\")  #reduce inference cost\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't provide information about future events or data that may not be available yet. Is there something else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='119880', response_metadata={'role': 'assistant', 'content': '119880', 'token_usage': {'prompt_tokens': 315, 'total_tokens': 317, 'completion_tokens': 2}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-aaba2582-3484-4d14-a06e-6cd5c438e6d2-0', role='assistant')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "client = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-8b-instruct\",\n",
    "  api_key=os.environ['NVIDIA_API_KEY'], \n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "\n",
    "llm_with_tools = client.bind_tools([tool])\n",
    "\n",
    "query = \"What is 120 * 999\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
